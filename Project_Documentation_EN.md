# üìä Complete Guide: Classification Model Development Project

---

## üéØ **Project Overview**

This project builds a **machine learning classification model** that predicts whether a user will purchase a product based on demographic information (age, salary, gender).

**Main Goal:** Build an ensemble model combining Logistic Regression and KNN with optimal performance.

---

## üìã **Project Workflow**

### **Stage 1Ô∏è‚É£: Environment Setup & Libraries**

```python
import numpy as np                      # Numerical operations
import pandas as pd                     # Data manipulation
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
import plotly.express as px             # Interactive visualizations
```

**Benefits:**
- NumPy & Pandas: Data handling
- Scikit-Learn: ML models & evaluation
- Plotly: Beautiful interactive charts

---

### **Stage 2Ô∏è‚É£: Data Loading**

```python
df = pd.read_csv('Social_Network_Ads.csv')
df.head(15)
```

**Dataset Structure:**

| User ID | Gender | Age | EstimatedSalary | Purchased |
|---------|--------|-----|-----------------|-----------|
| 15624510 | Male | 19 | 19000 | 0 |
| 15810944 | Male | 35 | 20000 | 0 |
| 15668575 | Female | 26 | 43000 | 0 |

**Features:**
- **User ID:** Unique identifier (no statistical value)
- **Gender:** Categorical feature (Male/Female)
- **Age:** Numerical feature
- **EstimatedSalary:** Numerical feature
- **Purchased:** Target variable (0 = No, 1 = Yes)

---

### **Stage 3Ô∏è‚É£: Exploratory Data Analysis (EDA)**

#### **3.1 Missing Values Check**

```python
df.isnull().sum()
# Result: No missing values ‚úì
```

#### **3.2 Data Balance**

```python
df['Gender'].value_counts()
# Female: 204
# Male: 196
# Result: Balanced data ‚úì
```

#### **3.3 Visualizations**

```python
# Box plot for Age distribution
fig = px.box(df, x='Age')

# Box plot for Salary distribution
fig = px.box(df, x='EstimatedSalary')

# Pie chart for Target balance
fig = px.pie(df, names='Purchased')
```

**Purpose:**
- **Box Plots:** Identify outliers
- **Pie Chart:** Check target class balance

---

### **Stage 4Ô∏è‚É£: Data Cleaning**

```python
# Remove User ID (no predictive value)
df = df.drop('User ID', axis=1)
```

**Reason:** User ID is a unique identifier with no statistical relevance.

---

### **Stage 5Ô∏è‚É£: Train-Test Split**

```python
X = df.drop('Purchased', axis=1)  # Features
y = df['Purchased']               # Target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    random_state=42,     # Reproducibility
    test_size=0.2,       # 20% test, 80% train
    stratify=y           # Maintain class balance
)
```

**Purpose:**
- **X_train (80%):** Model training data
- **X_test (20%):** Evaluation data
- **stratify=y:** Ensures class balance in both sets

**Why?** To test on unseen data (prevent overfitting) ‚úì

---

### **Stage 6Ô∏è‚É£: Creating Pipelines with Preprocessing**

#### **Problem: Data Leakage ‚ö†Ô∏è**

If we scale all data before splitting, we introduce **data leakage** ‚Üí model becomes overly optimistic about performance.

#### **Solution: Pipeline + Cross-Validation**

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import StratifiedKFold

# Define columns
num_cols = ['Age', 'EstimatedSalary']
cat_cols = ['Gender']

# Preprocessing steps
preprocess = ColumnTransformer(
    transformers=[
        # Numerical: Standardization
        ('num', StandardScaler(), num_cols),
        
        # Categorical: One-Hot Encoding
        ('cat', OneHotEncoder(
            drop='first',
            handle_unknown='ignore',
            sparse_output=False
        ), cat_cols),
    ]
)

# 5-Fold Cross-Validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
```

**What Happens:**

1. **StandardScaler:** Transforms to mean=0, std=1
   ```
   Age: [19, 35, 26] ‚Üí [-1.2, 0.8, 0.1]
   ```

2. **OneHotEncoding:** Converts categories to binary
   ```
   Gender: ['Male', 'Female'] ‚Üí [[1, 0], [0, 1]]
   ```

3. **StratifiedKFold:** Creates 5 balanced folds
   - Train on 4 folds, Test on 1 fold
   - Repeat 5 times

#### **Create Model Pipelines:**

```python
# Logistic Regression Pipeline
log_pipe = Pipeline([
    ('preprocess', preprocess),
    ('model', LogisticRegression(max_iter=1000))
])

# KNN Pipeline
knn_pipe = Pipeline([
    ('preprocess', preprocess),
    ('model', KNeighborsClassifier())
])
```

**Benefit:** Each fold gets separate preprocessing (no data leakage) ‚úì

---

### **Stage 7Ô∏è‚É£: Building Ensemble Model**

```python
from sklearn.ensemble import VotingClassifier

ensemble = VotingClassifier(
    estimators=[
        ('lr', log_pipe),
        ('knn', knn_pipe)
    ],
    voting='soft'  # Average probabilities
)
```

**Purpose:**
- Combines predictions from both models
- **voting='soft':** Takes average of probability estimates
  ```
  LR: 80% class 1
  KNN: 75% class 1
  Final: (80 + 75) / 2 = 77.5% class 1
  ```

**Benefit:** Ensemble typically outperforms individual models ‚úì

---

### **Stage 8Ô∏è‚É£: Hyperparameter Tuning with GridSearchCV**

```python
from sklearn.model_selection import GridSearchCV

# Parameters to test
param_grid = {
    'lr__model__C': [0.1, 1, 10],           # Regularization strength
    'knn__model__n_neighbors': [3, 5, 7, 9] # Number of neighbors
}

# Grid Search
grid = GridSearchCV(
    ensemble,
    param_grid=param_grid,
    cv=cv,
    scoring='f1',   # Evaluate using F1 Score
    n_jobs=-1       # Use all processors
)

# Train
grid.fit(X_train, y_train)
```

**Process:**
- Tests **3 √ó 4 = 12** parameter combinations
- Performs **5-fold cross-validation** for each
- Selects best combination based on F1 Score

**Result:**
```
Best Parameters: {'knn__model__n_neighbors': 5, 'lr__model__C': 1}
Best CV F1 Score: 0.87
```

---

### **Stage 9Ô∏è‚É£: Test Set Evaluation**

```python
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Get best model
model = grid.best_estimator_
y_pred = model.predict(X_test)

# Calculate accuracy
acc = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {acc:.2%}")  # 90.00%

# Detailed report
print(classification_report(y_test, y_pred))
```

**Results:**
```
              precision    recall  f1-score   support

           0       0.94      0.90      0.92        51
           1       0.84      0.90      0.87        29

    accuracy                           0.90        80
```

**Interpretation:**
- **Precision:** Of predicted purchases, 84% were correct
- **Recall:** Of actual purchases, model detected 90%
- **F1 Score:** Balanced harmonic mean = 0.87

---

### **Stage 1Ô∏è‚É£0Ô∏è‚É£: Confusion Matrix Visualization**

```python
# Plot confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix: Best Model')
plt.show()
```

**Matrix Interpretation:**
```
        Predicted
        0    1
Actual 0 [46   5]  ‚Üí 5 False Positives
       1 [ 3  26]  ‚Üí 3 False Negatives
```

---

## üîë **Key Concepts Explained**

### **1. Standardization (StandardScaler)**
```python
X_scaled = (X - mean) / std
# Result: All features have mean=0, std=1
# Importance: Many algorithms perform better with scaled data
```

### **2. One-Hot Encoding**
```python
# Original: Gender = ['Male', 'Female', 'Male']
# Encoded:
# Male ‚Üí [1, 0]
# Female ‚Üí [0, 1]
# Reason: ML algorithms need numeric input
```

### **3. Cross-Validation**
```python
# Instead of 1 split, create 5 different splits
# Train on 4 folds, test on 1 (repeat 5 times)
# Benefit: More reliable evaluation, less variance
```

### **4. Hyperparameter Tuning**
```python
# GridSearchCV tests all combinations:
# C = [0.1, 1, 10]
# n_neighbors = [3, 5, 7, 9]
# Total: 3 √ó 4 = 12 combinations
# Selects: Best performing combination
```

### **5. Ensemble Learning**
```python
# Instead of 1 model, use 2+ models
# Benefits: 
# - Better performance
# - More robust predictions
# - Reduces variance
```

---

## üìä **Final Model Performance**

| Metric | Value |
|--------|-------|
| **Accuracy** | 90% |
| **F1 Score** | 0.867 |
| **Precision** | 0.89 |
| **Recall** | 0.90 |

---

## ‚úÖ **Complete Project Workflow**

```
1. Load Data
   ‚Üì
2. Exploratory Data Analysis (EDA)
   ‚Üì
3. Data Cleaning
   ‚Üì
4. Train-Test Split (80/20)
   ‚Üì
5. Create Pipeline with Preprocessing
   ‚Üì
6. Build Ensemble Model
   ‚Üì
7. Hyperparameter Tuning (GridSearchCV)
   ‚Üì
8. Evaluate on Test Set
   ‚Üì
9. Visualize Results (Confusion Matrix)
   ‚Üì
10. Final Result: 90% Accuracy ‚úì
```

---

## üéì **Key Learning Outcomes**

‚úÖ Data loading and exploration (EDA)  
‚úÖ Importance of preprocessing and scaling  
‚úÖ Avoiding data leakage with pipelines  
‚úÖ Logistic Regression vs KNN algorithms  
‚úÖ Ensemble model creation  
‚úÖ Hyperparameter tuning with GridSearchCV  
‚úÖ Multiple evaluation metrics  
‚úÖ Cross-validation for robust assessment  

---

## üí° **Future Improvements**

1. **Try More Models:** Random Forest, SVM, Gradient Boosting, XGBoost
2. **Feature Engineering:** Create new features from existing ones
3. **Handle Class Imbalance:** Use SMOTE if imbalance exists
4. **Model Stacking:** Combine 3+ models
5. **Feature Selection:** Select most important features
6. **ROC-AUC Curve:** Additional performance metric
7. **Hyperparameter Optimization:** Use Bayesian Optimization instead of Grid Search

---

## üìù **Common Issues & Solutions**

| Issue | Solution |
|-------|----------|
| Data Leakage | Use Pipeline + CV |
| Overfitting | Use regularization (C parameter) |
| Poor Performance | Feature engineering, try other models |
| Imbalanced Data | Use SMOTE, class weights |
| Slow Training | Use RandomizedSearchCV instead of GridSearchCV |

---

## üéâ **Summary**

This is an excellent machine learning project demonstrating:
- Professional data handling
- Proper train-test split methodology
- Pipeline-based preprocessing
- Ensemble learning techniques
- Rigorous hyperparameter tuning
- Comprehensive model evaluation

**Result: A robust classification model with 90% accuracy!**

---

**Created with ‚ù§Ô∏è for Machine Learning Enthusiasts**
